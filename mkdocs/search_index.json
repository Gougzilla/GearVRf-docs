{
    "docs": [
        {
            "location": "/", 
            "text": "GearVR Framework Project\n\n\nThe Gear VR Framework (GearVRf) Project is a lightweight, powerful, open source rendering engine with a Java interface for developing mobile VR games and applications for Gear VR and Google Daydream View.\n\n\nGearVRf is:\n\n\n\n\n\n\nSimple\n - Java interface, Android Studio build environment and a simple SDK allow you to prototype rapidly. In-depth OpenGL and Oculus/Daydream rendering knowledge is not required. \n\n\n\n\n\n\nPowerful\n - VR-specific rendering optimizations and optional access to low-level graphics pipeline allow you to create and optimize high performance graphics.   \n\n\n\n\n\n\nOptimized for mobile\n - Built with mobile performance in mind, GearVRf provides easy and performance-oriented access to Android OS system level calls.  \n\n\n\n\n\n\nOpen source\n - that means no licensing fees or royalties \never\n, and active developer community contributions \n\n\n\n\n\n\nEfficient\n - GearVRf's interface layer is abstracted from the target mobile VR platform SDK. You can write code once and build for both Gear VR and Daydream/Cardboard. Default build options create a single apk that works for both, with run-time flow checks for Oculus service that revert to Daydream if Oculus not available. Google Cardboard is even supported, as Daydream's backend reverts to the Google Cardboard service if the mobile device does not support Daydream!\n\n\n\n\n\n\nGet Started", 
            "title": "Home"
        }, 
        {
            "location": "/#gearvr-framework-project", 
            "text": "The Gear VR Framework (GearVRf) Project is a lightweight, powerful, open source rendering engine with a Java interface for developing mobile VR games and applications for Gear VR and Google Daydream View.  GearVRf is:    Simple  - Java interface, Android Studio build environment and a simple SDK allow you to prototype rapidly. In-depth OpenGL and Oculus/Daydream rendering knowledge is not required.     Powerful  - VR-specific rendering optimizations and optional access to low-level graphics pipeline allow you to create and optimize high performance graphics.       Optimized for mobile  - Built with mobile performance in mind, GearVRf provides easy and performance-oriented access to Android OS system level calls.      Open source  - that means no licensing fees or royalties  ever , and active developer community contributions     Efficient  - GearVRf's interface layer is abstracted from the target mobile VR platform SDK. You can write code once and build for both Gear VR and Daydream/Cardboard. Default build options create a single apk that works for both, with run-time flow checks for Oculus service that revert to Daydream if Oculus not available. Google Cardboard is even supported, as Daydream's backend reverts to the Google Cardboard service if the mobile device does not support Daydream!    Get Started", 
            "title": "GearVR Framework Project"
        }, 
        {
            "location": "/getting_started/", 
            "text": "Software Requirements\n\n\nBefore start using GearVR Framework, make sure you download the following SDKs\n\n\n\n\nAndroid Studio\n\n\nJDK 1.7 or above\n\n\nOculus Mobile SDK\n\n\nGoogle VR SDK\n\n\n\n\nHardware Requirements\n\n\nGearVR Framework supports following devices\n\n\n\n\nGear VR compatible Samsung phone - Galaxy S8, Galaxy S8+, Galaxy S7, Galaxy S7 Edge, Note 5, Galaxy S6, Galaxy S6 Edge, Galaxy Edge+, Note 4\n\n\nSamsung Gear VR headset\n\n\nDaydream-ready phone\n\n\nGoogle Daydream View VR headset\n\n\n\n\nGetting Started\n\n\nGetting started with GearVR Framework in few simple steps\n\n\n\n\nDownload the \ntemplate project\n\n\nMake sure to download your \nOculus signature file\n and copy it under \napp\\src\\main\\assets\n folder\n\n\nOpen the project with Android Studio\n\n\nClick Run button and put on your VR device\n\n\n\n\n\n\nNote\n\n\nYou can test VR apps without headset, by enable Samsung VR service developer mode.\nSettings \n Applications \n manage applications \n Gear VR Service \n Manage Storage - press the VR Service Version 6 times. After that a 'You are a developer' message will appear.\n\n\n\n\n\n\nNote\n\n\nMake sure install your VR app with a valid oculus signature on the device first. Otherwise you'll see a 'You are not a developer' message.\n\n\n\n\n\n\nWarning\n\n\nScreen will keep blinking after you turn on the developer mode", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting_started/#software-requirements", 
            "text": "Before start using GearVR Framework, make sure you download the following SDKs   Android Studio  JDK 1.7 or above  Oculus Mobile SDK  Google VR SDK", 
            "title": "Software Requirements"
        }, 
        {
            "location": "/getting_started/#hardware-requirements", 
            "text": "GearVR Framework supports following devices   Gear VR compatible Samsung phone - Galaxy S8, Galaxy S8+, Galaxy S7, Galaxy S7 Edge, Note 5, Galaxy S6, Galaxy S6 Edge, Galaxy Edge+, Note 4  Samsung Gear VR headset  Daydream-ready phone  Google Daydream View VR headset", 
            "title": "Hardware Requirements"
        }, 
        {
            "location": "/getting_started/#getting-started", 
            "text": "Getting started with GearVR Framework in few simple steps   Download the  template project  Make sure to download your  Oculus signature file  and copy it under  app\\src\\main\\assets  folder  Open the project with Android Studio  Click Run button and put on your VR device    Note  You can test VR apps without headset, by enable Samsung VR service developer mode.\nSettings   Applications   manage applications   Gear VR Service   Manage Storage - press the VR Service Version 6 times. After that a 'You are a developer' message will appear.    Note  Make sure install your VR app with a valid oculus signature on the device first. Otherwise you'll see a 'You are not a developer' message.    Warning  Screen will keep blinking after you turn on the developer mode", 
            "title": "Getting Started"
        }, 
        {
            "location": "/tutorials/simple_vr_app/", 
            "text": "Overview\n\n\nAfter setting up GearVR Framework, let's create our first VR app and learn a few very important concept in the process.\n\n\nCreate Project\n\n\nThe easiest way to create a GearVR Framework project is by copying the \ntemplate project\n \n\n\nProject Structure\n\n\nBefore we start, let's take a look at some essential parts of fo a GearVR Framework app\n\n\n\n\nThe template project contains two classes, \nMainActivity\n and \nMainScene\n\n\n\n\n\n\nMainActivity\n is the entry point of the app, like \nandroid.app.Activity\n it handles the initialization and life cycle of a VR app.\n\n\n\n\n\n\nMainScene\n is the container of a scene, just like a scene in the movie, it contains things like camera, characters, visual effects etc, it is the place for all your VR content.\n\n\n\n\n\n\nIn the assets folder there are two files: \ngvr.xml\n and \noculussig\n file\n\n\n\n\n\n\ngvr.xml\n is where you config various behavior of GearVR framework, which we'll get into detail in future tutorials\n\n\n\n\n\n\noculussig\n is the oculus signing file which allows you to deploy debug apps to VR devices, so always make sure this you have a signing file in your project\n\n\n\n\n\n\nScene\n\n\nUsually a VR app/game consists of one or more scenes. The templeate project already created one Scene called \nMainScene\n and it should be the starting point for your VR project. \n\n\n\n\nNote\n\n\nMainScene\n extends from \nGVRMain\n, if you're creating your own entry point class, make sure to extend \nGVRMain\n\n\n\n\nThere are two functions in \nMainScene\n both are important for the scene to work\n\n\n\n\nonInit() is called when the scene is being loaded, can be used to perform actions like object creation, assets loading.\n\n\nonStep() called once per frame, can be used to perform things like animation, AI or user interactions\n\n\n\n\nAdd object\n\n\nAdding a object to the scene is simple, just create the object and specify the material and add it to the scene\n\n\nFirst let's add a new member varible for the Cube to the \nMainScene\n\n\n    \nGVRCubeSceneObject\n \nmCube\n\n\n\n\n\n\nThen add the cube to our scene with following code in \nonInit()\n function\n\n\n    \n//Create a cube\n\n    \nmCube\n \n=\n \nnew\n \nGVRCubeSceneObject\n(\ngvrContext\n);\n\n\n    \n//Set shader for the cube\n\n    \nmCube\n.\ngetRenderData\n().\nsetShaderTemplate\n(\nGVRPhongShader\n.\nclass\n);\n\n\n    \n//Set position of the cube at (0, -2, -3)\n\n    \nmCube\n.\ngetTransform\n().\nsetPosition\n(\n0\n,\n \n-\n2\n,\n \n-\n3\n);\n\n\n    \n//Add cube to the scene\n\n    \ngvrContext\n.\ngetMainScene\n().\naddSceneObject\n(\nmCube\n);\n\n\n\n\n\n\nBuild and run the app, you should be able to see a white cube on the screen\n\n\n\n\nNote\n\n\nIf you're using \"VR developer mode\" without headset the orentation might be different, you might need to turn around to see the cube\n\n\n\n\nMake it move\n\n\nNow let's make the cube rotate. Because we want to see the cube rotate continuously, we need to update it's rotation every frame. So instead of the \nonInit()\n function we need to add the rotation logic into \nonStep()\n function\n\n\nAdd the following code to the \nonStep()\n function\n\n\n    \n//Rotate the cube along the Y axis\n\n    \nmCube\n.\ngetTransform\n().\nrotateByAxis\n(\n1\n,\n \n0\n,\n \n1\n,\n \n0\n);\n\n\n\n\n\n\nBuild and run the app, you should be able to see a rotating cube.\n\n\nNow that you have a rotating cube in VR, feel free to try different things, how about, change it's color, make it scalue up and down or move it around.\n\n\nSource Code", 
            "title": "Simple VR app"
        }, 
        {
            "location": "/tutorials/simple_vr_app/#overview", 
            "text": "After setting up GearVR Framework, let's create our first VR app and learn a few very important concept in the process.", 
            "title": "Overview"
        }, 
        {
            "location": "/tutorials/simple_vr_app/#create-project", 
            "text": "The easiest way to create a GearVR Framework project is by copying the  template project", 
            "title": "Create Project"
        }, 
        {
            "location": "/tutorials/simple_vr_app/#project-structure", 
            "text": "Before we start, let's take a look at some essential parts of fo a GearVR Framework app   The template project contains two classes,  MainActivity  and  MainScene    MainActivity  is the entry point of the app, like  android.app.Activity  it handles the initialization and life cycle of a VR app.    MainScene  is the container of a scene, just like a scene in the movie, it contains things like camera, characters, visual effects etc, it is the place for all your VR content.    In the assets folder there are two files:  gvr.xml  and  oculussig  file    gvr.xml  is where you config various behavior of GearVR framework, which we'll get into detail in future tutorials    oculussig  is the oculus signing file which allows you to deploy debug apps to VR devices, so always make sure this you have a signing file in your project", 
            "title": "Project Structure"
        }, 
        {
            "location": "/tutorials/simple_vr_app/#scene", 
            "text": "Usually a VR app/game consists of one or more scenes. The templeate project already created one Scene called  MainScene  and it should be the starting point for your VR project.    Note  MainScene  extends from  GVRMain , if you're creating your own entry point class, make sure to extend  GVRMain   There are two functions in  MainScene  both are important for the scene to work   onInit() is called when the scene is being loaded, can be used to perform actions like object creation, assets loading.  onStep() called once per frame, can be used to perform things like animation, AI or user interactions", 
            "title": "Scene"
        }, 
        {
            "location": "/tutorials/simple_vr_app/#add-object", 
            "text": "Adding a object to the scene is simple, just create the object and specify the material and add it to the scene  First let's add a new member varible for the Cube to the  MainScene       GVRCubeSceneObject   mCube   Then add the cube to our scene with following code in  onInit()  function       //Create a cube \n     mCube   =   new   GVRCubeSceneObject ( gvrContext ); \n\n     //Set shader for the cube \n     mCube . getRenderData (). setShaderTemplate ( GVRPhongShader . class ); \n\n     //Set position of the cube at (0, -2, -3) \n     mCube . getTransform (). setPosition ( 0 ,   - 2 ,   - 3 ); \n\n     //Add cube to the scene \n     gvrContext . getMainScene (). addSceneObject ( mCube );   Build and run the app, you should be able to see a white cube on the screen   Note  If you're using \"VR developer mode\" without headset the orentation might be different, you might need to turn around to see the cube", 
            "title": "Add object"
        }, 
        {
            "location": "/tutorials/simple_vr_app/#make-it-move", 
            "text": "Now let's make the cube rotate. Because we want to see the cube rotate continuously, we need to update it's rotation every frame. So instead of the  onInit()  function we need to add the rotation logic into  onStep()  function  Add the following code to the  onStep()  function       //Rotate the cube along the Y axis \n     mCube . getTransform (). rotateByAxis ( 1 ,   0 ,   1 ,   0 );   Build and run the app, you should be able to see a rotating cube.  Now that you have a rotating cube in VR, feel free to try different things, how about, change it's color, make it scalue up and down or move it around.  Source Code", 
            "title": "Make it move"
        }, 
        {
            "location": "/tutorials/360_photo_app/", 
            "text": "Overview\n\n\nLast time we showed how easy it is to create a simple game scene, This time we're going to create an app for viewing 360 photos.\n\n\nTo display a photo in VR you first need to have a 360 photo. Then display the photo inside a sphere. When user look at the image from inside the sphere, it will create a immersive experience for the them. \n\n\nCreate Project\n\n\nMake a copy of \ntemplate project\n and copy your oculus signing files to the assets folder\n\n\nLoad Image\n\n\nIn order to display the image we need to load the image into the memory first. And here is how to do it.\n\n\n\n\n\n\ndownload a 360 photo from \nhere\n \n\n\n\n\n\n\nplace it under \n\\app\\src\\main\\res\\raw\n folder\n\n\n\n\n\n\nload image with the following code\n\n\n\n\n\n\nFuture\nGVRTexture\n \ntexture\n \n=\n \n    \ngvrContext\n.\ngetAssetLoader\n().\nloadFutureTexture\n(\n\n        \nnew\n \nGVRAndroidResource\n(\ngvrContext\n,\n \nR\n.\nraw\n.\nphotosphere\n)\n\n    \n);\n\n\n\n\n\n\n\n\nNote\n\n\nWe use loadFutureTexture because we want to load the texture asynchronously.\n\n\n\n\nCreate Sphere\n\n\nAdd the following code to create a sphere and apply the texture we previously loaded\n\n\n    \nGVRSphereSceneObject\n \nsphere\n \n=\n \n        \nnew\n \nGVRSphereSceneObject\n(\ngvrContext\n,\n \nfalse\n,\n \ntexture\n);\n\n\n    \n//Add Sphere to the scene\n\n    \ngvrContext\n.\ngetMainScene\n().\naddSceneObject\n(\nsphere\n);\n\n\n\n\n\n\n\n\nNote\n\n\nWe specify faceingOut parameter as false, because the player is inside the sphere looking out.\n\n\nYou can also specify the stack and slice parameter to make the sphere more smooth.", 
            "title": "360 Photo app"
        }, 
        {
            "location": "/tutorials/360_photo_app/#overview", 
            "text": "Last time we showed how easy it is to create a simple game scene, This time we're going to create an app for viewing 360 photos.  To display a photo in VR you first need to have a 360 photo. Then display the photo inside a sphere. When user look at the image from inside the sphere, it will create a immersive experience for the them.", 
            "title": "Overview"
        }, 
        {
            "location": "/tutorials/360_photo_app/#create-project", 
            "text": "Make a copy of  template project  and copy your oculus signing files to the assets folder", 
            "title": "Create Project"
        }, 
        {
            "location": "/tutorials/360_photo_app/#load-image", 
            "text": "In order to display the image we need to load the image into the memory first. And here is how to do it.    download a 360 photo from  here      place it under  \\app\\src\\main\\res\\raw  folder    load image with the following code    Future GVRTexture   texture   =  \n     gvrContext . getAssetLoader (). loadFutureTexture ( \n         new   GVRAndroidResource ( gvrContext ,   R . raw . photosphere ) \n     );    Note  We use loadFutureTexture because we want to load the texture asynchronously.", 
            "title": "Load Image"
        }, 
        {
            "location": "/tutorials/360_photo_app/#create-sphere", 
            "text": "Add the following code to create a sphere and apply the texture we previously loaded       GVRSphereSceneObject   sphere   =  \n         new   GVRSphereSceneObject ( gvrContext ,   false ,   texture ); \n\n     //Add Sphere to the scene \n     gvrContext . getMainScene (). addSceneObject ( sphere );    Note  We specify faceingOut parameter as false, because the player is inside the sphere looking out.  You can also specify the stack and slice parameter to make the sphere more smooth.", 
            "title": "Create Sphere"
        }, 
        {
            "location": "/programming_guide/overview/", 
            "text": "GearVR Framework Development Overview\n\n\nIntroduction to GearVRf integration and VR app development\n\n\nGearVRf provides tools to speed up development of advanced features in high quality VR applications. Available EGL extensions (including dual scan, front buffer, MSAA, and tile rendering) allow the best render quality.\n\n\nGearVRf is a native code 3D rendering engine with an Android library interface. You can build non-trivial content using only built-in objects. You can add new objects (such as scene objects with or without GL shaders) derived from classes or by overriding some methods - GearVRf takes care of all hardware handholding. You can do just about everything in Java - all source code is published, so you can easily add to or tweak native code.\n\n\nAnatomy of GearVRf Applications\n\n\nGearVRf is a framework which controls how and when your code is executed. Subclassing GearVRf objects allows you to add your own code. You can also listen to GearVRf events and provide callbacks that respond to them.\n\n\nA 3D scene is represented as a hierarchy of GearVRf scene objects. Each visible object has a triangle mesh describing its shape, a material describing its color properties and a transformation matrix controlling its position in the 3D world. You do not explicitly call OpenGL when using GearVRf. Instead, the GearVRF framework manages all rendering, providing a higher level abstraction for graphics.\n\n\nWhen constructing an Android application, you subclass the Activity class. Similarly, when constructing a GearVRF application you subclass GVRActivity, providing initialization code to create a GVRMain to set up the initial 3D scene and handle input events.\n\n\nDuring initialization, GVRActivity creates a GVRViewManager which does all the heavy lifting. This class is responsible for task scheduling, 3D rendering, animation and asset loading.\n\n\n\n\nThread Management\n\n\nOne key constraint of embedded GPU programming is that there is only one GL context. That is, all GPU commands must come from the same thread - the GL thread. The GPU should always be busy; therefore, the GL thread cannot be the main GUI thread.\n\n\nWhen starting GearVRf, your Android app creates the GL thread, puts the phone into stereoscopic mode, and supplies a pair of callback methods that run the app's startup and per-frame code on the GL thread. GearVRf provides methods for any thread to schedule runnable callbacks to the GL thread. All these callbacks mean that GearVRf programming is event-oriented on the GL thread in just the same way that Android programming is event-oriented on the GUI thread. Running two independent event systems on two independent threads does mean that you have to think about IPC whenever your Android Activity code on the GUI thread interacts with the GearVRf code on the GL thread. However, dual-thread operation also creates another huge section of your application that can take advantage of event atomicity. That is, callback events are method calls from a main loop - neither the GUI thread nor the GL thread ever runs more than one callback at one time, and each callback has to run to completion before any other callback can start on that thread. Your GL callbacks do not have to write code to keep other GL callbacks from seeing data structures in a partially updated state.\n\n\nScene Graph and Scene Objects\n\n\nYour startup code builds a scene graph made up of scene objects, and your per-frame code then manipulates the scene graph in real time. Each scene object has a 4x4 matrix that describes its position, orientation, and zoom relative to its parent. Each scene object can parent other scene objects, so complex objects can be composed of multiple small objects, each with its own shape and appearance, with all changing in synchrony. Each scene object provides methods to change its components using a lazy update pattern, which means that multiple updates per event cost very little more than a single update.\n\n\nYou make a scene object visible by adding a surface geometry and a skin. The geometry is a mesh of 3D triangles. GearVRf provides methods to build simple rectangular quads, and to load more complex meshes from files built by 3D model editors.\n\n\nEach material class contains the shader type, the GL identifier of a shader, values for all shader parameters, texture, and other uniform mappings. Each shader has two parts: a vertex shader and a fragment shader. The vertex shader is called for each vertex of each visible triangle and can compute triangle-specific values that are passed to the fragment shader, which draws each pixel of each visible triangle. GearVRf contains standard shaders that provide methods, such as simply sampling a texture (a bitmap image in GPU memory), without applying any lighting effects. You can create custom shaders by supplying vertex and fragment shaders and by declaring names to bind Java values to. The GL shader language is very simple and C-like; you can learn a lot by reading a few of the shaders in the sample applications.\n\n\nScene Graph\n\n\nThe scene graph describes the spatial relationship between objects in the scene. Each scene object has a 4x4 transformation matrix to position and orient it locally. The scene objects may be nested so that the transformations of the parent nodes are inherited by the children. This allows objects to be easily positioned and animated relative to one another.\n\n\nHere we see a scene graph for a butterfly with a body and two wings. Each scene object has a position and an orientation. The left and right wings can share the same mesh but it is positioned and oriented differently for each wing. The initial translation on the body is inherited by the wings. \n\n\n\n\nThe form of your scene graph can have implications for the performance of your application. Typically, having lots of small objects performs poorly compared to several large objects with a similar total vertex count. This is because there is a considerable amount of overhead in rendering a single object. GearVRf attempts to batch objects that do not move together to improve performance.\n\n\nPicking will work better on a spatially sorted scene graph. Grouping objects that are physically close together under a common ancestor will improve picking performance.\n\n\nTypes of Scene Objects\n\n\nYou can have invisible scene objects. These have a location and a set of child objects. This can be useful to move a set of scene objects as a unit preserving their relative geometry.\n\n\nVisible scene objects have a render data component attached which contains the geometry defining the shape of the object and a \nmaterial\n describing its appearance. The material contains the data that will be passed to the shader used by the GPU to draw the mesh.\n\n\nIn addition to displaying geometry, a scene object can display text, 360 photos, 360 video, normal photos and video, Android application view and internet browser views.\n\n\n\n\n\n\n\n\nScene Object Class\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nGVRSphereSceneObject\n\n\nconstructs sphere geometry\n\n\n\n\n\n\nGVRConeSceneObject\n\n\nconstructs cone geometry\n\n\n\n\n\n\nGVRCylinderSceneObject\n\n\nconstructs cylinder geometry\n\n\n\n\n\n\nGVRTextViewSceneObject\n\n\ndisplays text\n\n\n\n\n\n\nGVRVideoSceneObject\n\n\ndisplays a video\n\n\n\n\n\n\nGVRWebViewSceneObject\n\n\ndisplays an internet browser window\n\n\n\n\n\n\nGVRCameraSceneObject\n\n\ndisplays video from the phone camera\n\n\n\n\n\n\n\n\nScene Construction Example\n\n\nConstructing the initial GearVRF scene usually involves importing a set of assets and placing them relative to one another. In this example we make a simple butterfly with an ellipsoid for a body and textured planes for wings.\n\n\n    \nGVRContext\n \ncontext\n;\n\n    \nGVRTexture\n \nwingtex\n \n=\n \ncontext\n.\nloadTexture\n(\nnew\n \nGVRAndroidResource\n(\ncontext\n,\n \nR\n.\ndrawable\n.\nwingtex\n));\n\n    \nGVRSceneObject\n \nbody\n \n=\n \nnew\n \nGVRSphereObject\n(\ncontext\n);\n\n    \nGVRSceneObject\n \nleftwing\n \n=\n \nnew\n \nGVRSceneObject\n(\ncontext\n,\n \nwingtex\n);\n\n    \nGVRSceneObject\n \nrightwing\n \n=\n \nnew\n \nGVRSceneObject\n(\ncontext\n,\n \nwingtex\n);\n\n    \nleftwing\n.\ngetTransform\n().\nsetPosition\n(-\n1\n,\n \n0\n,\n \n0\n);\n\n    \nrightwing\n.\ngetTransform\n().\nsetPosition\n(\n1\n,\n \n0\n,\n \n0\n);\n\n    \nrightwing\n.\ngetTransform\n().\nsetRotationY\n(\n180\n);\n\n\n\n\n\n\nScene Object Components\n\n\nA scene object can have one or more components attached which provide additional capabilities. All scene objects have a GVRTransform component which supplies the 4x4 matrix used to position and orient the object in the scene. Attaching a GVRRenderData component referencing geometry and material properties will cause the geometry to be displayed in the scene.\n\n\nThe following components can be attached to a GVRSceneObject:\n\n\n\n\nGVRTransform - 4x4 transformation matrix\n\n\nGVRRenderData - geometry with material properties\n\n\nGVRLightBase - illumination source\n\n\nGVRCamera - camera\n\n\nGVRCameraRig - stereoscopic camera rig\n\n\nGVRCollider - collision geometry\n\n\nGVRBehavior - user defined component\n\n\n\n\nEach scene object can only have one component of a particular type. For example, you cannot attach two lights or two cameras to a single scene object. Components are retrieved and removed based on their type. When a component is attached to a scene object, it derives its position and orientation from the GVRTransform attached to that scene object.\n\n\n\n\n\n\n\n\nGVRSceneObject  function\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nGVRComponent getComponent(int type)\n\n\nGet the component of the specified class attached to the owner scene object.\n\n\n\n\n\n\nvoid attachComponent(GVRComponent)\n\n\nAttach the given component to the scene object.\n\n\n\n\n\n\nvoid detachComponent(GVRComponent)\n\n\nDetach the given component from the scene object.\n\n\n\n\n\n\nvoid detachComponenet(int type)\n\n\nDetach the component of the specified type from the scene object.\n\n\n\n\n\n\nList getAllComponents(int type)\n\n\nGet all components of the given type from the scene object and its children.", 
            "title": "Overview"
        }, 
        {
            "location": "/programming_guide/overview/#gearvr-framework-development-overview", 
            "text": "Introduction to GearVRf integration and VR app development  GearVRf provides tools to speed up development of advanced features in high quality VR applications. Available EGL extensions (including dual scan, front buffer, MSAA, and tile rendering) allow the best render quality.  GearVRf is a native code 3D rendering engine with an Android library interface. You can build non-trivial content using only built-in objects. You can add new objects (such as scene objects with or without GL shaders) derived from classes or by overriding some methods - GearVRf takes care of all hardware handholding. You can do just about everything in Java - all source code is published, so you can easily add to or tweak native code.", 
            "title": "GearVR Framework Development Overview"
        }, 
        {
            "location": "/programming_guide/overview/#anatomy-of-gearvrf-applications", 
            "text": "GearVRf is a framework which controls how and when your code is executed. Subclassing GearVRf objects allows you to add your own code. You can also listen to GearVRf events and provide callbacks that respond to them.  A 3D scene is represented as a hierarchy of GearVRf scene objects. Each visible object has a triangle mesh describing its shape, a material describing its color properties and a transformation matrix controlling its position in the 3D world. You do not explicitly call OpenGL when using GearVRf. Instead, the GearVRF framework manages all rendering, providing a higher level abstraction for graphics.  When constructing an Android application, you subclass the Activity class. Similarly, when constructing a GearVRF application you subclass GVRActivity, providing initialization code to create a GVRMain to set up the initial 3D scene and handle input events.  During initialization, GVRActivity creates a GVRViewManager which does all the heavy lifting. This class is responsible for task scheduling, 3D rendering, animation and asset loading.", 
            "title": "Anatomy of GearVRf Applications"
        }, 
        {
            "location": "/programming_guide/overview/#thread-management", 
            "text": "One key constraint of embedded GPU programming is that there is only one GL context. That is, all GPU commands must come from the same thread - the GL thread. The GPU should always be busy; therefore, the GL thread cannot be the main GUI thread.  When starting GearVRf, your Android app creates the GL thread, puts the phone into stereoscopic mode, and supplies a pair of callback methods that run the app's startup and per-frame code on the GL thread. GearVRf provides methods for any thread to schedule runnable callbacks to the GL thread. All these callbacks mean that GearVRf programming is event-oriented on the GL thread in just the same way that Android programming is event-oriented on the GUI thread. Running two independent event systems on two independent threads does mean that you have to think about IPC whenever your Android Activity code on the GUI thread interacts with the GearVRf code on the GL thread. However, dual-thread operation also creates another huge section of your application that can take advantage of event atomicity. That is, callback events are method calls from a main loop - neither the GUI thread nor the GL thread ever runs more than one callback at one time, and each callback has to run to completion before any other callback can start on that thread. Your GL callbacks do not have to write code to keep other GL callbacks from seeing data structures in a partially updated state.", 
            "title": "Thread Management"
        }, 
        {
            "location": "/programming_guide/overview/#scene-graph-and-scene-objects", 
            "text": "Your startup code builds a scene graph made up of scene objects, and your per-frame code then manipulates the scene graph in real time. Each scene object has a 4x4 matrix that describes its position, orientation, and zoom relative to its parent. Each scene object can parent other scene objects, so complex objects can be composed of multiple small objects, each with its own shape and appearance, with all changing in synchrony. Each scene object provides methods to change its components using a lazy update pattern, which means that multiple updates per event cost very little more than a single update.  You make a scene object visible by adding a surface geometry and a skin. The geometry is a mesh of 3D triangles. GearVRf provides methods to build simple rectangular quads, and to load more complex meshes from files built by 3D model editors.  Each material class contains the shader type, the GL identifier of a shader, values for all shader parameters, texture, and other uniform mappings. Each shader has two parts: a vertex shader and a fragment shader. The vertex shader is called for each vertex of each visible triangle and can compute triangle-specific values that are passed to the fragment shader, which draws each pixel of each visible triangle. GearVRf contains standard shaders that provide methods, such as simply sampling a texture (a bitmap image in GPU memory), without applying any lighting effects. You can create custom shaders by supplying vertex and fragment shaders and by declaring names to bind Java values to. The GL shader language is very simple and C-like; you can learn a lot by reading a few of the shaders in the sample applications.", 
            "title": "Scene Graph and Scene Objects"
        }, 
        {
            "location": "/programming_guide/overview/#scene-graph", 
            "text": "The scene graph describes the spatial relationship between objects in the scene. Each scene object has a 4x4 transformation matrix to position and orient it locally. The scene objects may be nested so that the transformations of the parent nodes are inherited by the children. This allows objects to be easily positioned and animated relative to one another.  Here we see a scene graph for a butterfly with a body and two wings. Each scene object has a position and an orientation. The left and right wings can share the same mesh but it is positioned and oriented differently for each wing. The initial translation on the body is inherited by the wings.    The form of your scene graph can have implications for the performance of your application. Typically, having lots of small objects performs poorly compared to several large objects with a similar total vertex count. This is because there is a considerable amount of overhead in rendering a single object. GearVRf attempts to batch objects that do not move together to improve performance.  Picking will work better on a spatially sorted scene graph. Grouping objects that are physically close together under a common ancestor will improve picking performance.", 
            "title": "Scene Graph"
        }, 
        {
            "location": "/programming_guide/overview/#types-of-scene-objects", 
            "text": "You can have invisible scene objects. These have a location and a set of child objects. This can be useful to move a set of scene objects as a unit preserving their relative geometry.  Visible scene objects have a render data component attached which contains the geometry defining the shape of the object and a  material  describing its appearance. The material contains the data that will be passed to the shader used by the GPU to draw the mesh.  In addition to displaying geometry, a scene object can display text, 360 photos, 360 video, normal photos and video, Android application view and internet browser views.     Scene Object Class  Description      GVRSphereSceneObject  constructs sphere geometry    GVRConeSceneObject  constructs cone geometry    GVRCylinderSceneObject  constructs cylinder geometry    GVRTextViewSceneObject  displays text    GVRVideoSceneObject  displays a video    GVRWebViewSceneObject  displays an internet browser window    GVRCameraSceneObject  displays video from the phone camera", 
            "title": "Types of Scene Objects"
        }, 
        {
            "location": "/programming_guide/overview/#scene-construction-example", 
            "text": "Constructing the initial GearVRF scene usually involves importing a set of assets and placing them relative to one another. In this example we make a simple butterfly with an ellipsoid for a body and textured planes for wings.       GVRContext   context ; \n     GVRTexture   wingtex   =   context . loadTexture ( new   GVRAndroidResource ( context ,   R . drawable . wingtex )); \n     GVRSceneObject   body   =   new   GVRSphereObject ( context ); \n     GVRSceneObject   leftwing   =   new   GVRSceneObject ( context ,   wingtex ); \n     GVRSceneObject   rightwing   =   new   GVRSceneObject ( context ,   wingtex ); \n     leftwing . getTransform (). setPosition (- 1 ,   0 ,   0 ); \n     rightwing . getTransform (). setPosition ( 1 ,   0 ,   0 ); \n     rightwing . getTransform (). setRotationY ( 180 );", 
            "title": "Scene Construction Example"
        }, 
        {
            "location": "/programming_guide/overview/#scene-object-components", 
            "text": "A scene object can have one or more components attached which provide additional capabilities. All scene objects have a GVRTransform component which supplies the 4x4 matrix used to position and orient the object in the scene. Attaching a GVRRenderData component referencing geometry and material properties will cause the geometry to be displayed in the scene.  The following components can be attached to a GVRSceneObject:   GVRTransform - 4x4 transformation matrix  GVRRenderData - geometry with material properties  GVRLightBase - illumination source  GVRCamera - camera  GVRCameraRig - stereoscopic camera rig  GVRCollider - collision geometry  GVRBehavior - user defined component   Each scene object can only have one component of a particular type. For example, you cannot attach two lights or two cameras to a single scene object. Components are retrieved and removed based on their type. When a component is attached to a scene object, it derives its position and orientation from the GVRTransform attached to that scene object.     GVRSceneObject  function  Description      GVRComponent getComponent(int type)  Get the component of the specified class attached to the owner scene object.    void attachComponent(GVRComponent)  Attach the given component to the scene object.    void detachComponent(GVRComponent)  Detach the given component from the scene object.    void detachComponenet(int type)  Detach the component of the specified type from the scene object.    List getAllComponents(int type)  Get all components of the given type from the scene object and its children.", 
            "title": "Scene Object Components"
        }, 
        {
            "location": "/programming_guide/features/", 
            "text": "features.md", 
            "title": "Features"
        }, 
        {
            "location": "/programming_guide/faq/", 
            "text": "1. Is there any example of object following the head tracking, just like a reticle?\n\n\nSee \ngvr-tutorial-lesson2 sample\n. Examine the BalloonMain.java and the headTracker tracker object it sets up. The key part is adding the object to the main camera rig.\n\n\n2. I want to implement a scrollable list of item like ListView in Android. How to go about that?\n\n\n\n\nBackground objects: rendering order N, depth test on\n\n\nClip object: rendering order N+1, depth test on, alpha blend on, alpha = 0 (completely transparent)\n\n\nList view object: rendering order N+2, depth test on\n\n\n\n\nThe clip object should be a plane with a hole in it where you want to see the list view. It should be completely transparent. It will be rendered after the background so it will update the depth buffer but the background will show thru completely. This clip object should have a Z value putting it IN FRONT of the list view object even though it will be rendered before that object (because you set the rendering order to a smaller value).\n\n\nGearVRF will render objects in ascending rendering order so the background will be rendered first. The clip object will update the depth buffer so that anything drawn BEHIND it will show thru the hole but will be obscured by the transparent clip area (the depth buffer will do the clipping for us).\n\n\n3. Can i use an emulator during development for testing?\n\n\nShort answer: No.\n\n\nLong answer: It would likely be somewhat painful to do. Oculus only provides 32bit arm libraries. Which means you would need to set up an arm emulator (rather than an x86 one). In that emulator, we would detect the oculus service is not on the system and fall back to daydream. However, in our experience, running an arm emulator is horrifically slow, especially for anything GL related. It's best to stick with a physical phone for development.\n\n\n4. I am using Windows, trying to build the framework and getting weird errors. Like this one:\n\n\n...\\GearVRf\\GVRf\\Framework\\framework\\..\\backend_oculus/src/main/jni/util/configuration_helper.cpp:235:1: fatal error: opening dependency file ./obj/local/armeabi-v7a/objs/...\\GearVRf\\GVRf\\Framework\\framework\\..\\backend_oculus/src/main/jni/util/configuration_helper.o.d: No such file or directory\n\n\n\n\n\nYour paths might be too long. Try moving the framework to C:\\ and build again.\n\n\n5. I want to inflate and show an Android view. Can I do that?\n\n\nYes. The gvr-renderableview sample shows how to do that.\n\n\n6. I want to use ExoPlayer instead of MediaPlayer for video playback. Can I do this?\n\n\nYes. See the gvr-360video sample, which allows you to use either. Set the USE_EXO_PLAYER flag in Minimal360VideoActivity.java.\n\n\n7. How can I create a mixed VR android app and launching VR Mode later, by clicking a button for example? I need to create an activity visualized in normal mode for settings and later launch a VR mode, showing the \"you need gear vr\" screen if you have not attached it.\n\n\nUnfortunately, this is not supported. Apps get marked as \"vr\" not individual activities. Which means the prompt will show when you try to launch your \"normal\" activity. This is not a gvrf limitation.\n\n\n8. Trying to build a sample but I get the following error:\n\n\nWhat\n \nwent\n \nwrong\n:\n\n\nExecution\n \nfailed\n \nfor\n \ntask\n \n:app:transformClassesWithDexForDebug\n.\n\n\n \ncom\n.\nandroid\n.\nbuild\n.\napi\n.\ntransform\n.\nTransformException\n:\n \ncom\n.\nandroid\n.\nide\n.\ncommon\n.\nprocess\n.\nProcessException\n:\n \njava\n.\nutil\n.\nconcurrent\n.\nExecutionException\n:\n \ncom\n.\nandroid\n.\ndex\n.\nDexException\n:\n \nMultiple\n \ndex\n \nfiles\n \ndefine\n \nLcom\n/\noculus\n/\nsystemutils\n/\nBuildConfig\n;\n\n\n\n\n\n\nMost likely you still have VrApi.jar and SystemUtils.jar under the framework module (GearVRf/GVRf/Framework/framework/src/main/libs/). Please remove them from there, clean and build.\n\n\n9. I am using Linux and getting a strange aapt error during the build. Something like \njava.io.IOException: Cannot run program \"/aapt\": error=2, No such file or directory\n\n\nYou might be missing support for executing 32bit binaries and/or libraries aapt depends on. Please run the following:\n\n\nsudo dpkg --add-architecture i386\nsudo apt-get update\nsudo apt-get install libc6:i386 libncurses5:i386 libstdc++6:i386\nsudo apt-get install zlib1g:i386\n\n\n\n\n\n10. Is there support for the Oculus Platform SDK?\n\n\nYes, the entitlement check is supported. Go to GVRf/Extensions/. There is a platformsdk_support module. To build it run \n./gradlew -Pplatformsdk_support=true platformsdk_support:assembleDebug\n. Checkout the javadoc in PlatformEntitlementCheck.java. Have been verified to work with Platform SDK versions 1.6, 1.7 and 1.8. For further information see \nhttps://github.com/Samsung/GearVRf/wiki/Entitlement-Check-using-GVRF\n\n\n11. Is there any way to play youtube video from url?\n\n\nYes. See \nhttps://github.com/Samsung/GearVRf/issues/1033#issuecomment-278244683\n\n\n12. I am trying to use GVRF on a Google Pixel phone and I get this exception:\n\n\n02-15 19:53:15.697 23156-23156/? E/AndroidRuntime: FATAL EXCEPTION: main\nProcess: pl.lynx.daydream.test, PID: 23156\njava.lang.UnsatisfiedLinkError: dalvik.system.PathClassLoader[DexPathList[[zip file \n/data/app/pl.lynx.daydream.test-2/base.apk\n],nativeLibraryDirectories=[/data/app/pl.lynx.daydream.test-2/lib/arm64, /system/fake-libs64, /data/app/pl.lynx.daydream.test-2/base.apk!/lib/arm64-v8a, /system/lib64, /vendor/lib64]]] couldn\nt find \nlibgvrf.so\n\n\n\n\n\n\nDaydream has 64bit binaries but GVRf only supports 32bit binaries. In your app's gradle file you need to add this:\n\n\nandroid {\n\n    // ignore the x86 and arm-v8 files from the google vr libraries\n    packagingOptions {\n        exclude \nlib/x86/libgvr.so\n\n        exclude \nlib/arm64-v8a/libgvr.so\n\n    }\n}\n\n\n\n\n\n13. I used to build the demos from the GearVRf-Demos repo just fine. Suddenly I am getting errors. What happened?\n\n\nThe master branch is subject to frequent improvements. The GVRf team pushes updated framework snapshots to the maven repo, but due to the gradle's caching you are most likely using outdated snapshot. Please pass the --refresh-dependencies argument to gradlew if you are building from the command line. Or you can just delete the gradle cache via \n\n\nrm -rf ~/.gradle/caches/.\n\n\n\n\n\nAlternatively you could use the 3.1 branch which is stable. After cloning the demos repo, switch to the release_v3.1 branch.\n\n\n14. I am building an app from scratch. How do I add support for GVRF to my app? What are the minimum dependencies?\n\n\nPlease see this bare-bones project that can serve as a reference: \nhttps://github.com/gearvrf/GearVRf-Demos/tree/master/template/GVRFApplication\n.\n\n\n15. My app in the Oculus Store fails to install on Android N devices. I get an UNTRUSTED_APK_ERROR error.\n\n\nOculus doesn't support APK signature scheme v2 yet. It should be disabled if you plan to submit apps to the Oculus store. Android Studio seems to apply the scheme unconditionally. Build from the command line and include the following section in your gradle file:\n\n\nandroid {\n    signingConfigs {\n        release {\n            v2SigningEnabled false\n            storeFile file(\nfull-path-to-your-store-file\n)\n            storePassword \nyour_store_pwd\n\n            keyAlias \nalias\n\n            keyPassword \nkey_pwd\n\n        }\n    }\n    defaultConfig {\n        signingConfig signingConfigs.release\n    }\n}\n\n\n\n\n\n16. Can you run GearVR app on your phone without GearVR?\n\n\nYes, in your phone's Settings-\nApplications-\nApplication Manager-\nGear VR Service-\nManage Storage Tab on VR Service Version multiple times until the 'Developer Options' menu appears. Then flick on the 'Developer mode' switch. You may need to do this every time when the phone restarts\n\n\n17. How to reduce nausea?\n\n\nMaintain a high frame-rate, such as 90+ fps.\n\n\n18. How many triangles can I display max for a good VR experience with high frame rate?\n\n\nOn a mobile phone such as Galaxy S6/S7, please keep triangle count in the thousands to tens of thousands range if possible, depending on shader complexities.\n\n\n19. What are some graphics performance tips?\n\n\nKeep draw calls minimal and relatively cheap pixel shader. Keep in mind shadows from shadow map more or less doubles the triangle rendered. Use profiler to see if you are really GPU bound.\n\n\n20. Which phones are compatible with GearVR?\n\n\nCurrently, Samsung Galaxy S6, S6 Edge, S6 Edge+, S7, S7 Edge, S7 Edge+, S8, S8+, Note 5", 
            "title": "FAQ"
        }, 
        {
            "location": "/programming_guide/faq/#1-is-there-any-example-of-object-following-the-head-tracking-just-like-a-reticle", 
            "text": "See  gvr-tutorial-lesson2 sample . Examine the BalloonMain.java and the headTracker tracker object it sets up. The key part is adding the object to the main camera rig.", 
            "title": "1. Is there any example of object following the head tracking, just like a reticle?"
        }, 
        {
            "location": "/programming_guide/faq/#2-i-want-to-implement-a-scrollable-list-of-item-like-listview-in-android-how-to-go-about-that", 
            "text": "Background objects: rendering order N, depth test on  Clip object: rendering order N+1, depth test on, alpha blend on, alpha = 0 (completely transparent)  List view object: rendering order N+2, depth test on   The clip object should be a plane with a hole in it where you want to see the list view. It should be completely transparent. It will be rendered after the background so it will update the depth buffer but the background will show thru completely. This clip object should have a Z value putting it IN FRONT of the list view object even though it will be rendered before that object (because you set the rendering order to a smaller value).  GearVRF will render objects in ascending rendering order so the background will be rendered first. The clip object will update the depth buffer so that anything drawn BEHIND it will show thru the hole but will be obscured by the transparent clip area (the depth buffer will do the clipping for us).", 
            "title": "2. I want to implement a scrollable list of item like ListView in Android. How to go about that?"
        }, 
        {
            "location": "/programming_guide/faq/#3-can-i-use-an-emulator-during-development-for-testing", 
            "text": "Short answer: No.  Long answer: It would likely be somewhat painful to do. Oculus only provides 32bit arm libraries. Which means you would need to set up an arm emulator (rather than an x86 one). In that emulator, we would detect the oculus service is not on the system and fall back to daydream. However, in our experience, running an arm emulator is horrifically slow, especially for anything GL related. It's best to stick with a physical phone for development.", 
            "title": "3. Can i use an emulator during development for testing?"
        }, 
        {
            "location": "/programming_guide/faq/#4-i-am-using-windows-trying-to-build-the-framework-and-getting-weird-errors-like-this-one", 
            "text": "...\\GearVRf\\GVRf\\Framework\\framework\\..\\backend_oculus/src/main/jni/util/configuration_helper.cpp:235:1: fatal error: opening dependency file ./obj/local/armeabi-v7a/objs/...\\GearVRf\\GVRf\\Framework\\framework\\..\\backend_oculus/src/main/jni/util/configuration_helper.o.d: No such file or directory  Your paths might be too long. Try moving the framework to C:\\ and build again.", 
            "title": "4. I am using Windows, trying to build the framework and getting weird errors. Like this one:"
        }, 
        {
            "location": "/programming_guide/faq/#5-i-want-to-inflate-and-show-an-android-view-can-i-do-that", 
            "text": "Yes. The gvr-renderableview sample shows how to do that.", 
            "title": "5. I want to inflate and show an Android view. Can I do that?"
        }, 
        {
            "location": "/programming_guide/faq/#6-i-want-to-use-exoplayer-instead-of-mediaplayer-for-video-playback-can-i-do-this", 
            "text": "Yes. See the gvr-360video sample, which allows you to use either. Set the USE_EXO_PLAYER flag in Minimal360VideoActivity.java.", 
            "title": "6. I want to use ExoPlayer instead of MediaPlayer for video playback. Can I do this?"
        }, 
        {
            "location": "/programming_guide/faq/#7-how-can-i-create-a-mixed-vr-android-app-and-launching-vr-mode-later-by-clicking-a-button-for-example-i-need-to-create-an-activity-visualized-in-normal-mode-for-settings-and-later-launch-a-vr-mode-showing-the-you-need-gear-vr-screen-if-you-have-not-attached-it", 
            "text": "Unfortunately, this is not supported. Apps get marked as \"vr\" not individual activities. Which means the prompt will show when you try to launch your \"normal\" activity. This is not a gvrf limitation.", 
            "title": "7. How can I create a mixed VR android app and launching VR Mode later, by clicking a button for example? I need to create an activity visualized in normal mode for settings and later launch a VR mode, showing the \"you need gear vr\" screen if you have not attached it."
        }, 
        {
            "location": "/programming_guide/faq/#8-trying-to-build-a-sample-but-i-get-the-following-error", 
            "text": "What   went   wrong :  Execution   failed   for   task   :app:transformClassesWithDexForDebug .    com . android . build . api . transform . TransformException :   com . android . ide . common . process . ProcessException :   java . util . concurrent . ExecutionException :   com . android . dex . DexException :   Multiple   dex   files   define   Lcom / oculus / systemutils / BuildConfig ;   Most likely you still have VrApi.jar and SystemUtils.jar under the framework module (GearVRf/GVRf/Framework/framework/src/main/libs/). Please remove them from there, clean and build.", 
            "title": "8. Trying to build a sample but I get the following error:"
        }, 
        {
            "location": "/programming_guide/faq/#9-i-am-using-linux-and-getting-a-strange-aapt-error-during-the-build-something-like-javaioioexception-cannot-run-program-aapt-error2-no-such-file-or-directory", 
            "text": "You might be missing support for executing 32bit binaries and/or libraries aapt depends on. Please run the following:  sudo dpkg --add-architecture i386\nsudo apt-get update\nsudo apt-get install libc6:i386 libncurses5:i386 libstdc++6:i386\nsudo apt-get install zlib1g:i386", 
            "title": "9. I am using Linux and getting a strange aapt error during the build. Something like java.io.IOException: Cannot run program \"/aapt\": error=2, No such file or directory"
        }, 
        {
            "location": "/programming_guide/faq/#10-is-there-support-for-the-oculus-platform-sdk", 
            "text": "Yes, the entitlement check is supported. Go to GVRf/Extensions/. There is a platformsdk_support module. To build it run  ./gradlew -Pplatformsdk_support=true platformsdk_support:assembleDebug . Checkout the javadoc in PlatformEntitlementCheck.java. Have been verified to work with Platform SDK versions 1.6, 1.7 and 1.8. For further information see  https://github.com/Samsung/GearVRf/wiki/Entitlement-Check-using-GVRF", 
            "title": "10. Is there support for the Oculus Platform SDK?"
        }, 
        {
            "location": "/programming_guide/faq/#11-is-there-any-way-to-play-youtube-video-from-url", 
            "text": "Yes. See  https://github.com/Samsung/GearVRf/issues/1033#issuecomment-278244683", 
            "title": "11. Is there any way to play youtube video from url?"
        }, 
        {
            "location": "/programming_guide/faq/#12-i-am-trying-to-use-gvrf-on-a-google-pixel-phone-and-i-get-this-exception", 
            "text": "02-15 19:53:15.697 23156-23156/? E/AndroidRuntime: FATAL EXCEPTION: main\nProcess: pl.lynx.daydream.test, PID: 23156\njava.lang.UnsatisfiedLinkError: dalvik.system.PathClassLoader[DexPathList[[zip file  /data/app/pl.lynx.daydream.test-2/base.apk ],nativeLibraryDirectories=[/data/app/pl.lynx.daydream.test-2/lib/arm64, /system/fake-libs64, /data/app/pl.lynx.daydream.test-2/base.apk!/lib/arm64-v8a, /system/lib64, /vendor/lib64]]] couldn t find  libgvrf.so   Daydream has 64bit binaries but GVRf only supports 32bit binaries. In your app's gradle file you need to add this:  android {\n\n    // ignore the x86 and arm-v8 files from the google vr libraries\n    packagingOptions {\n        exclude  lib/x86/libgvr.so \n        exclude  lib/arm64-v8a/libgvr.so \n    }\n}", 
            "title": "12. I am trying to use GVRF on a Google Pixel phone and I get this exception:"
        }, 
        {
            "location": "/programming_guide/faq/#13-i-used-to-build-the-demos-from-the-gearvrf-demos-repo-just-fine-suddenly-i-am-getting-errors-what-happened", 
            "text": "The master branch is subject to frequent improvements. The GVRf team pushes updated framework snapshots to the maven repo, but due to the gradle's caching you are most likely using outdated snapshot. Please pass the --refresh-dependencies argument to gradlew if you are building from the command line. Or you can just delete the gradle cache via   rm -rf ~/.gradle/caches/.  Alternatively you could use the 3.1 branch which is stable. After cloning the demos repo, switch to the release_v3.1 branch.", 
            "title": "13. I used to build the demos from the GearVRf-Demos repo just fine. Suddenly I am getting errors. What happened?"
        }, 
        {
            "location": "/programming_guide/faq/#14-i-am-building-an-app-from-scratch-how-do-i-add-support-for-gvrf-to-my-app-what-are-the-minimum-dependencies", 
            "text": "Please see this bare-bones project that can serve as a reference:  https://github.com/gearvrf/GearVRf-Demos/tree/master/template/GVRFApplication .", 
            "title": "14. I am building an app from scratch. How do I add support for GVRF to my app? What are the minimum dependencies?"
        }, 
        {
            "location": "/programming_guide/faq/#15-my-app-in-the-oculus-store-fails-to-install-on-android-n-devices-i-get-an-untrusted_apk_error-error", 
            "text": "Oculus doesn't support APK signature scheme v2 yet. It should be disabled if you plan to submit apps to the Oculus store. Android Studio seems to apply the scheme unconditionally. Build from the command line and include the following section in your gradle file:  android {\n    signingConfigs {\n        release {\n            v2SigningEnabled false\n            storeFile file( full-path-to-your-store-file )\n            storePassword  your_store_pwd \n            keyAlias  alias \n            keyPassword  key_pwd \n        }\n    }\n    defaultConfig {\n        signingConfig signingConfigs.release\n    }\n}", 
            "title": "15. My app in the Oculus Store fails to install on Android N devices. I get an UNTRUSTED_APK_ERROR error."
        }, 
        {
            "location": "/programming_guide/faq/#16-can-you-run-gearvr-app-on-your-phone-without-gearvr", 
            "text": "Yes, in your phone's Settings- Applications- Application Manager- Gear VR Service- Manage Storage Tab on VR Service Version multiple times until the 'Developer Options' menu appears. Then flick on the 'Developer mode' switch. You may need to do this every time when the phone restarts", 
            "title": "16. Can you run GearVR app on your phone without GearVR?"
        }, 
        {
            "location": "/programming_guide/faq/#17-how-to-reduce-nausea", 
            "text": "Maintain a high frame-rate, such as 90+ fps.", 
            "title": "17. How to reduce nausea?"
        }, 
        {
            "location": "/programming_guide/faq/#18-how-many-triangles-can-i-display-max-for-a-good-vr-experience-with-high-frame-rate", 
            "text": "On a mobile phone such as Galaxy S6/S7, please keep triangle count in the thousands to tens of thousands range if possible, depending on shader complexities.", 
            "title": "18. How many triangles can I display max for a good VR experience with high frame rate?"
        }, 
        {
            "location": "/programming_guide/faq/#19-what-are-some-graphics-performance-tips", 
            "text": "Keep draw calls minimal and relatively cheap pixel shader. Keep in mind shadows from shadow map more or less doubles the triangle rendered. Use profiler to see if you are really GPU bound.", 
            "title": "19. What are some graphics performance tips?"
        }, 
        {
            "location": "/programming_guide/faq/#20-which-phones-are-compatible-with-gearvr", 
            "text": "Currently, Samsung Galaxy S6, S6 Edge, S6 Edge+, S7, S7 Edge, S7 Edge+, S8, S8+, Note 5", 
            "title": "20. Which phones are compatible with GearVR?"
        }, 
        {
            "location": "/programming_guide/video_tutorials/", 
            "text": "video_tutorials.md", 
            "title": "Video Tutorials"
        }, 
        {
            "location": "/programming_guide/sample_code/", 
            "text": "sample_code.md", 
            "title": "Sample Code"
        }, 
        {
            "location": "/about/contribution/", 
            "text": "Contribution.md", 
            "title": "Contribution"
        }, 
        {
            "location": "/about/release_notes/", 
            "text": "release_notes.md", 
            "title": "Release Notes"
        }, 
        {
            "location": "/about/roadmap/", 
            "text": "roadmap.md", 
            "title": "Roadmap"
        }, 
        {
            "location": "/about/license/", 
            "text": "license.md", 
            "title": "License"
        }, 
        {
            "location": "/about/privacy_policy/", 
            "text": "privacy_policy.md", 
            "title": "Privacy Policy"
        }, 
        {
            "location": "/about/marketing_resource/", 
            "text": "marketing_resource.md", 
            "title": "Marketing Resources"
        }
    ]
}